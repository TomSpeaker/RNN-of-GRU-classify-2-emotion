import os
import pickle
import numpy as np
from tensorflow.keras.preprocessing.sequence import pad_sequences
from model import build_model  # å¼•å…¥æ¨¡å‹ç»“æ„

# å‚æ•°è®¾ç½®
max_len = 200
input_dim = 10000
output_dim = 128
weights_path = "gru_weights.h5"
tokenizer_path = "tokenizer.pkl"

# åŠ è½½åˆ†è¯å™¨
if not os.path.exists(tokenizer_path):
    raise FileNotFoundError("âŒ æœªæ‰¾åˆ° tokenizer.pklï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹ç”Ÿæˆåˆ†è¯å™¨")
with open(tokenizer_path, "rb") as f:
    tokenizer = pickle.load(f)
print("ğŸ“¦ å·²åŠ è½½åˆ†è¯å™¨")

# æ„å»ºæ¨¡å‹
model = build_model(input_dim=input_dim, output_dim=output_dim, input_length=max_len)

# åŠ è½½æ¨¡å‹å‚æ•°
if not os.path.exists(weights_path):
    raise FileNotFoundError("âŒ æœªæ‰¾åˆ°æ¨¡å‹æƒé‡ gru_weights.h5ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹ä¿å­˜æƒé‡")
model.load_weights(weights_path)
print("âœ… æ¨¡å‹å·²åŠ è½½å®Œæ¯•ï¼Œå¯ä»¥è¿›è¡Œé¢„æµ‹ï¼")

# è¿›å…¥é¢„æµ‹å¾ªç¯
print("\nğŸ¯ è¾“å…¥ä¸€æ®µè‹±æ–‡å½±è¯„å†…å®¹ï¼Œæ¨¡å‹å°†é¢„æµ‹å…¶æƒ…æ„Ÿå€¾å‘ï¼ˆè¾“å…¥ q æˆ– quit é€€å‡ºï¼‰")
while True:
    user_input = input("è¯·è¾“å…¥å½±è¯„å†…å®¹ï¼š").strip()
    if user_input.lower() in ['q', 'quit']:
        print("ğŸ‘‹ é€€å‡ºæµ‹è¯•")
        break

    # æ–‡æœ¬é¢„å¤„ç†
    seq = tokenizer.texts_to_sequences([user_input])
    pad_seq = pad_sequences(seq, maxlen=max_len, padding='post', truncating='post')

    # æ¨¡å‹é¢„æµ‹
    pred = model.predict(pad_seq)[0][0]
    label = int(pred >= 0.5)
    label_text = "ç§¯æ" if label == 1 else "æ¶ˆæ"

    print(f"ğŸ“¢ æ¨¡å‹é¢„æµ‹ï¼š{label_text}ï¼ˆæ¦‚ç‡å€¼ï¼š{pred:.4f}ï¼‰\n")
